## APF

This is a tensorflow implementation of paper "[Adversarial Privacy-preserving Filter](https://arxiv.org/abs/2007.12861)" at  *ACM Multimedia 2020*.

Fawkes is a privacy protection system developed by researchers at [SANDLab](https://sandlab.cs.uchicago.edu/), University of Chicago. For more information about the project, please refer to our project [webpage](https://sandlab.cs.uchicago.edu/fawkes/). Contact us at fawkes-team@googlegroups.com. 

We published an academic paper to summarize our work "[Fawkes: Protecting Personal Privacy against Unauthorized Deep Learning Models](https://www.shawnshan.com/files/publication/fawkes.pdf)" at *USENIX Security 2020*. 

NEW! If you would like to use Fawkes to protect your identity, please check out our software and binary implementation on the [website](https://sandlab.cs.uchicago.edu/fawkes/#code). 



## Copyright

This code is intended only for personal privacy protection or academic research. 

## Running Environment

- Python 3.7.7 
- pillow, scipy, numpy ...
- tensorflow 1.15.0
- mxnet 1.3.1 (only needed when reading mxrec file)

## Pretrained Model

Here we will open our pretrained models for easier application soon.


## Citation
```
@inproceedings{zhang2020adversarial,
  title={Adversarial Privacy-preserving Filter},
  author={Zhang, Jiaming and Sang, Jitao and Zhao, Xian and Huang, Xiaowen and Sun, Yanfeng and Hu, Yongli},
  booktitle="Proceedings of the 28th ACM International Conference on Multimedia",
  year={2020}
}
```
